{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:59:22.985375Z",
     "start_time": "2025-05-08T12:59:22.975447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ],
   "id": "4a7bdb5dcf241719",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:59:23.129021Z",
     "start_time": "2025-05-08T12:59:23.072272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Setup basic logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class SimpleSparkSession:\n",
    "    \"\"\"Simple Spark session builder for Jupyter notebooks\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            app_name=\"Jupyter Spark Session\",\n",
    "            master=\"local[*]\",\n",
    "            spark_config=None,\n",
    "            enable_hive_support=False,\n",
    "            # S3 configuration\n",
    "            s3_bucket_name=None,\n",
    "            s3_endpoint=None,\n",
    "            s3_access_key=None,\n",
    "            s3_secret_key=None,\n",
    "            s3_region=\"us-east-1\",\n",
    "            s3_path_style_access=True,\n",
    "            # PostgreSQL configuration\n",
    "            postgres_config=None,\n",
    "            # Package configuration\n",
    "            packages=None\n",
    "    ):\n",
    "        self.app_name = app_name\n",
    "        self.master = master\n",
    "        self.spark_config = spark_config or {}\n",
    "        self.enable_hive_support = enable_hive_support\n",
    "\n",
    "        # S3 config\n",
    "        self.s3_bucket_name = s3_bucket_name\n",
    "        self.s3_endpoint = s3_endpoint\n",
    "        self.s3_access_key = s3_access_key\n",
    "        self.s3_secret_key = s3_secret_key\n",
    "        self.s3_region = s3_region\n",
    "        self.s3_path_style_access = s3_path_style_access\n",
    "\n",
    "        # PostgreSQL config\n",
    "        self.postgres_config = postgres_config\n",
    "        self.jdbc_driver_path: Optional[str] = None\n",
    "\n",
    "        # Packages\n",
    "        self.packages = packages or []\n",
    "\n",
    "        self._session = None\n",
    "\n",
    "    def build_session(self):\n",
    "        \"\"\"Build and return a SparkSession\"\"\"\n",
    "        if self._session is not None:\n",
    "            return self._session\n",
    "\n",
    "        # Start building the session\n",
    "        builder = SparkSession.builder.appName(self.app_name).master(self.master)\n",
    "\n",
    "        builder = builder.config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "            .config(\"spark.driver.extraJavaOptions\", \"-Djava.security.manager=allow\") \\\n",
    "            .config(\"spark.executor.extraJavaOptions\", \"-Djava.security.manager=allow\") \\\n",
    " \\\n",
    "            # Add Hive support if requested\n",
    "        if self.enable_hive_support:\n",
    "            builder = builder.enableHiveSupport()\n",
    "\n",
    "        if self.jdbc_driver_path:\n",
    "            builder = builder.config(\"spark.driver.extraClassPath\", self.jdbc_driver_path)\n",
    "            builder = builder.config(\"spark.executor.extraClassPath\", self.jdbc_driver_path)\n",
    "\n",
    "        # Add all configuration options\n",
    "        for key, value in self.spark_config.items():\n",
    "            builder = builder.config(key, value)\n",
    "\n",
    "        # Configure packages\n",
    "        if self.packages:\n",
    "            packages = \",\".join(self.packages)\n",
    "            builder = builder.config(\"spark.jars.packages\", packages)\n",
    "\n",
    "        # Add S3 configuration if credentials provided\n",
    "        if self.s3_access_key and self.s3_secret_key:\n",
    "            builder = builder.config(\"spark.hadoop.fs.s3a.access.key\", self.s3_access_key)\n",
    "            builder = builder.config(\"spark.hadoop.fs.s3a.secret.key\", self.s3_secret_key)\n",
    "            builder = builder.config(\"spark.hadoop.fs.s3a.aws.credentials.provider\",\n",
    "                                     \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "\n",
    "            # Config for non-AWS S3\n",
    "            if self.s3_endpoint:\n",
    "                builder = builder.config(\"spark.hadoop.fs.s3a.endpoint\", self.s3_endpoint)\n",
    "                builder = builder.config(\"spark.hadoop.fs.s3a.endpoint.region\", self.s3_region)\n",
    "\n",
    "            # Path style access for non-AWS implementations\n",
    "            if self.s3_path_style_access:\n",
    "                builder = builder.config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "                builder = builder.config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "                builder = builder.config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "                builder = builder.config(\"spark.hadoop.fs.s3a.multiobjectdelete.enable\", \"false\")\n",
    "\n",
    "        # Build the session\n",
    "        logger.info(f\"Building Spark session with app name: {self.app_name}, master: {self.master}\")\n",
    "        self._session = builder.getOrCreate()\n",
    "\n",
    "        return self._session\n",
    "\n",
    "    def get_session(self):\n",
    "        \"\"\"Get the current SparkSession or create a new one\"\"\"\n",
    "        return self.build_session()\n",
    "\n",
    "    def stop_session(self):\n",
    "        \"\"\"Stop the current Spark session if it exists\"\"\"\n",
    "        if self._session is not None:\n",
    "            self._session.stop()\n",
    "            self._session = None\n",
    "            logger.info(\"Spark session stopped\")"
   ],
   "id": "8b2bb162eb09d731",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:59:25.225422Z",
     "start_time": "2025-05-08T12:59:23.136199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark = SimpleSparkSession(\n",
    "    app_name=\"Data Analysis Notebook\",\n",
    "    packages=[\n",
    "        \"org.postgresql:postgresql:42.5.4\",\n",
    "        \"org.apache.hadoop:hadoop-aws:3.3.4\",\n",
    "        \"com.amazonaws:aws-java-sdk-bundle:1.12.426\"\n",
    "    ],\n",
    "    s3_access_key=os.getenv(\"S3_ACCESS_KEY\"),\n",
    "    s3_secret_key=os.getenv(\"S3_SECRET_KEY\"),\n",
    "    s3_endpoint=os.getenv(\"S3_ENDPOINT\"),\n",
    "    s3_region=\"garage\",\n",
    "    s3_path_style_access=True,\n",
    "    postgres_config={\n",
    "        \"user\": os.getenv(\"POSTGRES_USER\"),\n",
    "        \"password\": os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "        \"driver\": \"org.postgresql.Driver\",\n",
    "        \"currentSchema\": \"public\"\n",
    "    },\n",
    "    enable_hive_support=False,\n",
    "    s3_bucket_name=\"traffy-troffi\"\n",
    ").get_session()"
   ],
   "id": "34bc065afbc5a0fc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Building Spark session with app name: Data Analysis Notebook, master: local[*]\n",
      "25/05/08 19:59:23 WARN Utils: Your hostname, PatrickChoDevMacbook.local resolves to a loopback address: 127.0.0.1; using 10.201.246.45 instead (on interface en0)\n",
      "25/05/08 19:59:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/patrick/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/patrick/.ivy2/jars\n",
      "org.postgresql#postgresql added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "com.amazonaws#aws-java-sdk-bundle added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-e61a6dca-8a5a-4030-91ac-77a21cb09f00;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.postgresql#postgresql;42.5.4 in central\n",
      "\tfound org.checkerframework#checker-qual;3.5.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.426 in central\n",
      ":: resolution report :: resolve 85ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.426 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.5.0 from central in [default]\n",
      "\torg.postgresql#postgresql;42.5.4 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 by [com.amazonaws#aws-java-sdk-bundle;1.12.426] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   6   |   0   |   0   |   1   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-e61a6dca-8a5a-4030-91ac-77a21cb09f00\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/2ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/patrick/Desktop/Workspace/Projects/traffy-troffi/.venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/08 19:59:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:59:25.810957Z",
     "start_time": "2025-05-08T12:59:25.230352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = spark.read.jdbc(table='traffy_fondue',\n",
    "                     url=\"jdbc:postgresql://localhost:5432/traffy-troffi\",\n",
    "                     properties={\"user\": \"postgres\", \"password\": \"troffi\",\n",
    "                                 \"driver\": \"org.postgresql.Driver\",\n",
    "                                 \"currentSchema\": \"public\"}\n",
    "                     )\n",
    "df.printSchema()"
   ],
   "id": "3831892c8309fa70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ticket_id: string (nullable = true)\n",
      " |-- complaint: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- image: string (nullable = true)\n",
      " |-- image_after: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- district: string (nullable = true)\n",
      " |-- subdistrict: string (nullable = true)\n",
      " |-- categories: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- categories_idx: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:59:25.841141Z",
     "start_time": "2025-05-08T12:59:25.839457Z"
    }
   },
   "cell_type": "code",
   "source": "import pyspark.sql.functions as F",
   "id": "4363751b6abf68e1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:59:27.071855Z",
     "start_time": "2025-05-08T12:59:25.975574Z"
    }
   },
   "cell_type": "code",
   "source": "df.filter((F.col(\"district\") == 'ราชเทวี') & (F.array_contains('categories', 'ถนน'))).show()",
   "id": "d6a376a72faa63c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+--------------------+--------------------+--------+---------+--------+-----------+--------------------+-----------------+\n",
      "|  ticket_id|           complaint|           timestamp|               image|         image_after|latitude|longitude|district|subdistrict|          categories|   categories_idx|\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+--------+---------+--------+-----------+--------------------+-----------------+\n",
      "|2024-UPZB93|รบกวนช่วยทำพื้นถน...|2024-09-09 11:44:...|https://storage.g...|https://storage.g...| 13.7548|100.54201| ราชเทวี|   ถนนพญาไท|               [ถนน]|            [9.0]|\n",
      "|2024-KTGPQY|บริเวณนี้มีการเปิ...|2024-05-07 14:25:...|https://storage.g...|https://storage.g...|13.75871|100.54239| ราชเทวี|   ถนนพญาไท|               [ถนน]|            [9.0]|\n",
      "|2024-K3PRE6|จุดนี้มืดและเปลี่...|2024-11-01 05:02:...|https://storage.g...|https://storage.g...|13.75672|100.52418| ราชเทวี|  ทุ่งพญาไท|[แสงสว่าง, ถนน, ค...| [23.0, 9.0, 6.0]|\n",
      "|2024-BRUQ8W|ถนนราชวิถีช่วงก่อ...|2024-05-02 09:46:...|https://storage.g...|https://storage.g...|13.76619| 100.5359| ราชเทวี|  ทุ่งพญาไท|        [ถนน, จราจร]|       [9.0, 7.0]|\n",
      "|2024-628FCL|*ถนน พระราม6 มุ่ง...|2024-07-24 04:24:...|https://storage.g...|https://storage.g...|13.76074|100.52516| ราชเทวี|  ทุ่งพญาไท|               [ถนน]|            [9.0]|\n",
      "|2024-9HFGT9|ถนนพระราม6 มีซากร...|2024-09-13 01:50:...|https://storage.g...|https://storage.g...|13.75678|100.52396| ราชเทวี|  ทุ่งพญาไท|      [กีดขวาง, ถนน]|       [2.0, 9.0]|\n",
      "|2024-K3NRY2| ร้านค้าปิดถนนขายของ|2024-05-08 11:30:...|https://storage.g...|https://storage.g...|13.75189|100.53489| ราชเทวี|ถนนเพชรบุรี|               [ถนน]|            [9.0]|\n",
      "|2024-M3ANTN|            ถนนชำรุด|2024-10-02 06:52:...|https://storage.g...|https://storage.g...| 13.7608|100.52797| ราชเทวี|  ทุ่งพญาไท|               [ถนน]|            [9.0]|\n",
      "|2024-FC8ERW|พบว่ามีบุคคลนำพื้...|2024-05-02 09:43:...|https://storage.g...|https://storage.g...|13.76566|100.52842| ราชเทวี|  ทุ่งพญาไท|      [กีดขวาง, ถนน]|       [2.0, 9.0]|\n",
      "|2024-BNVWBY|ซอยเพชรบุรี 5 แขว...|2024-05-14 11:41:...|https://storage.g...|https://storage.g...|13.75639| 100.5293| ราชเทวี|  ทุ่งพญาไท|[น้ำท่วม, ถนน, ร้...|[12.0, 9.0, 15.0]|\n",
      "|2024-HCBFHK|มีร้านขายอาหาร แล...|2024-05-13 06:27:...|https://storage.g...|https://storage.g...|13.75323|100.54204| ราชเทวี|   มักกะสัน|      [กีดขวาง, ถนน]|       [2.0, 9.0]|\n",
      "|2024-KNDDBH|เกาะหลางถนนไม่สวยเลย|2024-09-04 03:25:...|https://storage.g...|https://storage.g...|13.74964|100.54085| ราชเทวี|ถนนเพชรบุรี|               [ถนน]|            [9.0]|\n",
      "|2024-QYCGRU|หน้าปากซอยทางเข้า...|2024-05-27 07:55:...|https://storage.g...|https://storage.g...|13.75192|100.52574| ราชเทวี|ถนนเพชรบุรี|               [ถนน]|            [9.0]|\n",
      "|2024-GPU2K3|ตรงใต้สะพานห้างพา...|2024-10-17 04:05:...|https://storage.g...|https://storage.g...|13.74987|100.54216| ราชเทวี|   มักกะสัน|[สะพาน, ถนน, ความ...| [17.0, 9.0, 5.0]|\n",
      "|2024-N2TCL8|ถนนชำรุดเป็นหลุมเ...|2024-05-06 05:34:...|https://storage.g...|https://storage.g...|13.74955|100.53108| ราชเทวี|ถนนเพชรบุรี|               [ถนน]|            [9.0]|\n",
      "|2024-DPYNL7|หลุมบ่อมีน้ำขังสะ...|2024-05-27 07:59:...|https://storage.g...|https://storage.g...|13.75182|100.52591| ราชเทวี|ถนนเพชรบุรี|               [ถนน]|            [9.0]|\n",
      "|2024-6XHBZ9|หน้าห้างแพลตตินั่...|2024-05-09 07:47:...|https://storage.g...|https://storage.g...|13.75056|100.53909| ราชเทวี|ถนนเพชรบุรี|               [ถนน]|            [9.0]|\n",
      "|2024-DPZYG9|หลุมบ่อกลางถนนบริ...|2024-07-09 05:53:...|https://storage.g...|https://storage.g...|13.75215|100.52589| ราชเทวี|ถนนเพชรบุรี|               [ถนน]|            [9.0]|\n",
      "|2024-3HXNUZ|กิ่งไม้ยาวมาออกมา...|2024-05-08 08:00:...|https://storage.g...|https://storage.g...|13.76115|100.53685| ราชเทวี|   ถนนพญาไท|               [ถนน]|            [9.0]|\n",
      "|2024-BFAX79|หน้าห้างแพลตตินั่...|2024-05-09 07:40:...|https://storage.g...|https://storage.g...|13.75056|100.53899| ราชเทวี|ถนนเพชรบุรี|      [กีดขวาง, ถนน]|       [2.0, 9.0]|\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+--------+---------+--------+-----------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:59:27.252936Z",
     "start_time": "2025-05-08T12:59:27.091903Z"
    }
   },
   "cell_type": "code",
   "source": "df.filter((F.col(\"district\") == 'ราชเทวี') & (F.array_contains('categories', 'ถนน'))).sample(0.1).show()",
   "id": "f06acc14a916a03f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+--------------------+--------------------+--------+---------+--------+-----------+--------------------+--------------------+\n",
      "|  ticket_id|           complaint|           timestamp|               image|         image_after|latitude|longitude|district|subdistrict|          categories|      categories_idx|\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+--------+---------+--------+-----------+--------------------+--------------------+\n",
      "|2024-628FCL|*ถนน พระราม6 มุ่ง...|2024-07-24 04:24:...|https://storage.g...|https://storage.g...|13.76074|100.52516| ราชเทวี|  ทุ่งพญาไท|               [ถนน]|               [9.0]|\n",
      "|2024-DPZYG9|หลุมบ่อกลางถนนบริ...|2024-07-09 05:53:...|https://storage.g...|https://storage.g...|13.75215|100.52589| ราชเทวี|ถนนเพชรบุรี|               [ถนน]|               [9.0]|\n",
      "|2024-N8B26R|ถนนชำรุดค่ะ ทำให้...|2024-05-23 07:32:...|https://storage.g...|https://storage.g...|13.75246|100.54147| ราชเทวี|   ถนนพญาไท|    [ถนน, ความสะอาด]|          [9.0, 6.0]|\n",
      "|2024-P287TL|กลับรถในทางห้ามซึ...|2024-05-31 09:47:...|https://storage.g...|https://storage.g...|13.75162|100.53558| ราชเทวี|ถนนเพชรบุรี|               [ถนน]|               [9.0]|\n",
      "|2024-CK82W2|รถขายของมาขายฝากถ...|2024-09-27 16:07:...|https://storage.g...|https://storage.g...|13.75219|100.53471| ราชเทวี|ถนนเพชรบุรี|               [ถนน]|               [9.0]|\n",
      "|2024-EAVHGM|ถนนข้างทางหน้าร้า...|2024-06-08 14:21:...|https://storage.g...|https://storage.g...|13.74959|100.54322| ราชเทวี|   มักกะสัน|               [ถนน]|               [9.0]|\n",
      "|2024-DLU29Q|กิ่งไม้ละหัวคนเดิ...|2024-06-07 07:26:...|https://storage.g...|https://storage.g...|13.76873|100.52811| ราชเทวี|  ทุ่งพญาไท|        [สะพาน, ถนน]|         [17.0, 9.0]|\n",
      "|2024-8VXC8U|ถนนเป็นหลุมขนาดให...|2024-06-12 02:58:...|https://storage.g...|https://storage.g...|13.75747|100.53561| ราชเทวี|   ถนนพญาไท|      [ถนน, ทางเท้า]|         [9.0, 10.0]|\n",
      "|2024-KCB8B2|บนสะพานลอย ถนนเพช...|2024-06-20 11:54:...|https://storage.g...|https://storage.g...|13.75201|100.53523| ราชเทวี|ถนนเพชรบุรี|[คนจรจัด, ความปลอ...|[3.0, 5.0, 9.0, 2.0]|\n",
      "|2024-FALD76|ถนนปรับปรุงลาดยาง...|2024-06-25 08:11:...|https://storage.g...|https://storage.g...|13.76388|100.53777| ราชเทวี|   ถนนพญาไท|[ท่อระบายน้ำ, ถนน...|    [11.0, 9.0, 5.0]|\n",
      "|2024-HT7NX7|เห็นเดินอยู่แต่แถ...|2025-01-14 15:24:...|https://storage.g...|https://storage.g...|13.76321|100.54253| ราชเทวี|   ถนนพญาไท|               [ถนน]|               [9.0]|\n",
      "|2024-486VP6|แจ้งถนนเลนที่2 มี...|2024-09-30 05:23:...|https://storage.g...|https://storage.g...|13.74849|100.56328| ราชเทวี|   มักกะสัน|[ท่อระบายน้ำ, ถนน...|    [11.0, 9.0, 5.0]|\n",
      "|2024-CPZPZ9|บริเวณนี้ผมสังเกต...|2024-06-27 05:55:...|https://storage.g...|https://storage.g...|13.75144|100.56384| ราชเทวี|   มักกะสัน|               [ถนน]|               [9.0]|\n",
      "|2024-LBTCL2|มีรถขนปูนหลายคันจ...|2024-07-01 04:40:...|https://storage.g...|https://storage.g...|13.75678|100.52376| ราชเทวี|  ทุ่งพญาไท|        [จราจร, ถนน]|          [7.0, 9.0]|\n",
      "|2024-CPNFL4|ตอนเช้าๆช่วงประมา...|2024-07-24 04:16:...|https://storage.g...|https://storage.g...|13.75515|100.52316| ราชเทวี|ถนนเพชรบุรี|[ทางเท้า, ความปลอ...|    [10.0, 5.0, 9.0]|\n",
      "|2024-7MZXN3|รถเข็นขายหมูปิ้ง ...|2024-08-09 17:25:...|https://storage.g...|https://storage.g...|13.74834|100.55423| ราชเทวี|   มักกะสัน|[จราจร, กีดขวาง, ...|     [7.0, 2.0, 9.0]|\n",
      "|2024-GA6CMH|ขยะและรถจอดขวาง ป...|2024-07-19 08:24:...|https://storage.g...|https://storage.g...|13.75262|100.52621| ราชเทวี|ถนนเพชรบุรี|    [ความสะอาด, ถนน]|          [6.0, 9.0]|\n",
      "|2024-NVEP9V|เทลาดยางทำถนนใหม่...|2024-11-13 06:47:...|https://storage.g...|https://storage.g...|13.75601|100.54273| ราชเทวี|   มักกะสัน|  [ความปลอดภัย, ถนน]|          [5.0, 9.0]|\n",
      "|2024-7AACZF|ทางม้าลายหน้า รพ....|2024-08-13 08:46:...|https://storage.g...|https://storage.g...|13.76714|100.53488| ราชเทวี|  ทุ่งพญาไท|  [ความปลอดภัย, ถนน]|          [5.0, 9.0]|\n",
      "|2024-KAGDCM|พื้นถนน ยางมะตอยหลุด|2024-08-25 09:09:...|https://storage.g...|https://storage.g...|13.74992|100.53116| ราชเทวี|ถนนเพชรบุรี|               [ถนน]|               [9.0]|\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+--------+---------+--------+-----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:59:33.318839Z",
     "start_time": "2025-05-08T12:59:27.277071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"phor2547/final-dsde-type\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ").to(device)"
   ],
   "id": "54e934b33b9f6a66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:59:34.526275Z",
     "start_time": "2025-05-08T12:59:33.359820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "all_predictions = []\n",
    "inputs = tokenizer(\n",
    "    [row.complaint for row in\n",
    "     df.filter((F.col(\"district\") == 'ราชเทวี') & (F.array_contains(F.col(\"categories\"), 'ถนน'))).sample(0.01).select(\n",
    "         \"complaint\").collect()],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = torch.sigmoid(logits).cpu().numpy()\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    # Convert each prediction row to encoded format\n",
    "    encoded_predictions = []\n",
    "    for pred_row in preds:\n",
    "        # Get indices where value is 1\n",
    "        positive_indices = np.where(pred_row == 1)[0]\n",
    "        encoded_predictions.append(positive_indices.tolist())\n",
    "\n",
    "    all_predictions.extend(encoded_predictions)\n",
    "\n",
    "all_predictions"
   ],
   "id": "c4e83c5273dfcd3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9],\n",
       " [9],\n",
       " [9],\n",
       " [5, 9],\n",
       " [5, 9],\n",
       " [9, 23],\n",
       " [7, 9, 10],\n",
       " [2, 9],\n",
       " [2, 7, 9],\n",
       " [5],\n",
       " [9],\n",
       " [2, 9],\n",
       " [9],\n",
       " [7, 9],\n",
       " [5, 9, 21, 23],\n",
       " [9],\n",
       " [5, 9],\n",
       " [9],\n",
       " [9],\n",
       " [9, 15],\n",
       " [2, 7, 9],\n",
       " [2, 7, 9],\n",
       " [9],\n",
       " [9],\n",
       " [9, 19],\n",
       " [9],\n",
       " [9],\n",
       " [9],\n",
       " [6, 9, 10],\n",
       " [5, 9]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:59:35.598068Z",
     "start_time": "2025-05-08T12:59:34.565548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, IntegerType\n",
    "\n",
    "# Store the complaint rows to maintain order and for later joining\n",
    "filtered_rows = df.filter(\n",
    "    (F.col(\"district\") == 'ราชเทวี') &\n",
    "    (F.array_contains(F.col(\"categories\"), 'ถนน'))\n",
    ").sample(0.01)\n",
    "\n",
    "# Keep track of row identifiers (assuming there's an ID column; if not, we'll create one)\n",
    "row_ids = [row.ticket_id for row in\n",
    "           filtered_rows.select(\"ticket_id\").collect()]  # Adjust if your ID column has a different name\n",
    "\n",
    "complaints = [row.complaint for row in filtered_rows.select(\"complaint\").collect()]\n",
    "\n",
    "inputs = tokenizer(\n",
    "    complaints,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(device)\n",
    "\n",
    "encoded_predictions = []\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = torch.sigmoid(logits).cpu().numpy()\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    # Convert each prediction row to encoded format\n",
    "    for pred_row in preds:\n",
    "        # Get indices where value is 1\n",
    "        positive_indices = np.where(pred_row == 1)[0]\n",
    "        encoded_predictions.append(positive_indices.tolist())\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "predictions_df = spark.createDataFrame(\n",
    "    [(id, pred) for id, pred in zip(row_ids, encoded_predictions)],\n",
    "    [\"ticket_id\", \"encoded_predictions\"]\n",
    ")\n",
    "\n",
    "# Join the predictions with the original filtered DataFrame\n",
    "result_df = filtered_rows.join(\n",
    "    predictions_df,\n",
    "    on=\"ticket_id\",\n",
    "    how=\"left\"\n",
    ")"
   ],
   "id": "1b9eb6a55060d26a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:59:36.300240Z",
     "start_time": "2025-05-08T12:59:35.645494Z"
    }
   },
   "cell_type": "code",
   "source": "result_df.show()",
   "id": "28092b9c02c04731",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+--------------------+--------------------+--------+---------+--------+-----------+--------------------+--------------------+-------------------+\n",
      "|  ticket_id|           complaint|           timestamp|               image|         image_after|latitude|longitude|district|subdistrict|          categories|      categories_idx|encoded_predictions|\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+--------+---------+--------+-----------+--------------------+--------------------+-------------------+\n",
      "|2022-KW4PD8|แท๊กซี่จอดตรงป้าย...|2022-08-14 15:13:...|https://storage.g...|https://storage.g...|13.76683|100.52798| ราชเทวี|  ทุ่งพญาไท|               [ถนน]|               [9.0]|                [9]|\n",
      "|2024-PCR67G|ด้านหน้ารร สุโกศล...|2024-01-10 05:47:...|https://storage.g...|https://storage.g...|13.75796|100.53594| ราชเทวี|   ถนนพญาไท|               [ถนน]|               [9.0]|                [9]|\n",
      "|2024-MQ6CV2|มีจุดทิ้งขยะอยู่ห...|2024-09-04 02:51:...|https://storage.g...|https://storage.g...|13.75346| 100.5264| ราชเทวี|ถนนเพชรบุรี|    [ความสะอาด, ถนน]|          [6.0, 9.0]|                [6]|\n",
      "|2023-DWKX3R|ถนนนิคมมักกะสันจา...|2023-03-17 08:15:...|https://storage.g...|https://storage.g...| 13.7546|100.54363| ราชเทวี|   มักกะสัน|               [ถนน]|               [9.0]|                [9]|\n",
      "|2022-ABWMRG|ถนน นานาเหนือ รถว...|2022-08-22 07:23:...|https://storage.g...|https://storage.g...|13.74938| 100.5544| ราชเทวี|   มักกะสัน|        [ถนน, จราจร]|          [9.0, 7.0]|             [7, 9]|\n",
      "|2023-AHBMBK|ถนนหน้า รพ.รามา แ...|2024-05-30 01:43:...|https://storage.g...|https://storage.g...|13.76838|100.52875| ราชเทวี|  ทุ่งพญาไท|               [ถนน]|               [9.0]|                [9]|\n",
      "|2023-MQDUP8|แท็กซี่ สามล้อ ๆล...|2023-12-15 12:13:...|https://storage.g...|https://storage.g...|13.75145|100.53718| ราชเทวี|   ถนนพญาไท|[จราจร, กีดขวาง, ...|     [7.0, 2.0, 9.0]|          [2, 7, 9]|\n",
      "|2024-4NN6RM|มีครอบครัวนอนอยู่...|2024-11-07 04:19:...|https://storage.g...|https://storage.g...|13.76343|100.53731| ราชเทวี|  ทุ่งพญาไท|  [ถนน, ความปลอดภัย]|          [9.0, 5.0]|             [5, 9]|\n",
      "|2024-G3ATZ4|เก็บขยะ ปิดถนนในซ...|2024-02-13 02:35:...|https://storage.g...|https://storage.g...|13.75326|100.53825| ราชเทวี|   ถนนพญาไท|[การเดินทาง, ถนน,...|     [1.0, 9.0, 2.0]|          [1, 2, 9]|\n",
      "|2022-GT6WBB|1. ปัญหาถนนพระราม...|2023-12-13 07:17:...|https://storage.g...|https://storage.g...|13.76923|100.52876| ราชเทวี|  ทุ่งพญาไท|               [ถนน]|               [9.0]|                [9]|\n",
      "|2022-BZNRDU|            ถนนชำรุด|2023-06-15 04:08:...|https://storage.g...|https://storage.g...|13.75739|100.53419| ราชเทวี|   ถนนพญาไท|               [ถนน]|               [9.0]|                [9]|\n",
      "|2022-FNDPC2|มาจากแยกถนนพญาไท ...|2022-06-22 04:11:...|https://storage.g...|https://storage.g...| 13.7505|100.54019| ราชเทวี|   ถนนพญาไท|               [ถนน]|               [9.0]|                [9]|\n",
      "|2024-AMCYPW|แท็กซี่ สามล้อ ๆล...|2024-02-20 03:04:...|https://storage.g...|https://storage.g...|13.75153|100.53717| ราชเทวี|   ถนนพญาไท|[กีดขวาง, ถนน, จร...|     [2.0, 9.0, 7.0]|          [2, 7, 9]|\n",
      "|2024-BVE9VV|ป้ายโฆษณาขนาดใหญ่...|2024-11-06 03:55:...|https://storage.g...|https://storage.g...|13.74941|100.54339| ราชเทวี|   มักกะสัน|[ทางเท้า, ถนน, คว...|[10.0, 9.0, 5.0, ...|      [2, 5, 9, 10]|\n",
      "|2024-6GRMMD|ถนนเพชรบุรีตัดใหม...|2024-10-28 04:06:...|https://storage.g...|https://storage.g...|13.74949|100.55824| ราชเทวี|   มักกะสัน|               [ถนน]|               [9.0]|                [9]|\n",
      "|2022-APYNXK|มีการก่อสร้างถนนห...|2022-07-31 13:50:...|https://storage.g...|https://storage.g...|13.76202|100.52505| ราชเทวี|  ทุ่งพญาไท|               [ถนน]|               [9.0]|             [0, 9]|\n",
      "|2023-6FND4D|ทางเท้าถนนนี้เสีย...|2023-12-25 03:51:...|https://storage.g...|https://storage.g...|13.75651|100.53943| ราชเทวี|   ถนนพญาไท|      [ถนน, ทางเท้า]|         [9.0, 10.0]|            [9, 10]|\n",
      "|2022-6TEHEK|2.ถนนจตุรทิศ กลาง...|2023-05-12 06:46:...|https://storage.g...|https://storage.g...|13.75387|100.56268| ราชเทวี|   มักกะสัน|[แสงสว่าง, ถนน, ค...|    [23.0, 9.0, 5.0]|         [5, 9, 23]|\n",
      "|2023-74QUL6|แท็กซี่ สามล้อ ๆล...|2023-12-25 08:07:...|https://storage.g...|https://storage.g...|13.75143|100.53716| ราชเทวี|   ถนนพญาไท|[กีดขวาง, ถนน, จร...|     [2.0, 9.0, 7.0]|          [2, 7, 9]|\n",
      "|2024-44GHC4|ขุดเจาะถนนภายในซอ...|2024-03-13 10:03:...|https://storage.g...|https://storage.g...|13.75306| 100.5336| ราชเทวี|   ถนนพญาไท|        [PM2.5, ถนน]|          [0.0, 9.0]|             [0, 9]|\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+--------+---------+--------+-----------+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:59:37.196857Z",
     "start_time": "2025-05-08T12:59:36.351505Z"
    }
   },
   "cell_type": "code",
   "source": "spark.stop()",
   "id": "b0694c7747f71b17",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T12:59:37.257250Z",
     "start_time": "2025-05-08T12:59:37.255496Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6f70f2c8c3fe311a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
